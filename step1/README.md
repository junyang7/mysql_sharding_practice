阶段2：单库多表
====
将原有大表拆分成小表
拆分规则：
    1个库n(n=32)张表
    每个库的表的数量固定不变
    库扩容时每次增加原有一倍容量
    中间变量：kid % (库数量 * n)
    库：中间变量 / n
    表：中间变量 % n

旧数据库：db
旧数据表：tb
数据库名保持不变，在数据库内部对大表进行拆分
新数据表：tb_n(n∈[0,31])

步骤
====
创建数据表:
    tb_n(n∈[0,31])
修改配置：
    基表：
        启用路由：是
        写：新旧
        读：旧
    依赖：
        业务代码调用DAO时传入路由kid（提前做）
        框架底层对tb基表的所有写操作（insert,update,delete,replace等）在原有写逻辑上增加按照新路由规则双写语句（将待写入的SQL复制一条，修改表名，一起执行）
    结果：
        insert写会立即实现双写
        只需要最多全量扫描2遍旧表tb，将不存在新表的数据拿出来写入新表或存在的数据覆盖即可
        扫描采用主键ID降序分页批量法（新增导致ID变大，但新增数据已经实现了双写了，没必要扫描了）
        扫描2遍的原因是：
            对于一个未迁移的数据，有可能在迁移的过程发生变化，而此时新表中并没有，因此只会影响旧表。当完成第1遍迁移后，新表旧表数据几乎全部一致，需要再完全覆盖1遍才能保证最终数据一致性。
            因为一旦数据迁移到了新表，即便是数据不一致，也会在下次发生变化是被纠正。同时为了100%保证数据一致，再做一次覆盖会比较保险。
        要求：
            所有参数不能使用基于原生SQL的某个字段的值得运算，必须全部是已经计算好的参数。暴力要求业务逻辑不使用原生SQL，必须使用框架封装的方法。
            
后台进程：
    对tb表采用主键ID降序分页批量读取数据：如果数据在新表tb_n中不存在，则执行插入；如果存在，则执行覆盖
    此过程需要执行2遍
    结果：
        完成tb=>tb_n(n∈[0,31])数据迁移
        此后，旧表和新表数据完全一致
修改配置：
    基表：
        启用路由：是
        写：新旧
        读：新
    结果：
        数据双写，旧表与新表数据一致
        读取新表，验证逻辑，如果出错，可以继续同步数据，直到一致。如果出现不可容忍的事故，则读取旧表，实现回滚
修改配置：
    基表：
        启用路由：是
        写：新
        读：新
    结果：
        读写均操作新表，完成大表拆分

实验
====
与今天下午的方案有改动，需要实际模拟验证一下可行性
此方案优点在于服务完全不受影响

思考
====
只拆分瓶颈大表，还是关联表全拆，一步到位？
框架对数据库的配置需要支持对基表的读写控制：
    启用路由：否（默认），是
    写：旧（默认），新，新旧
    读：旧（默认），新
    ----
    新旧可以用单和多来标识比较有意义，旧表就是一张大表，新表就是多张表
    